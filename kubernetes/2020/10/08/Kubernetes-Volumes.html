<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Kubernetes Volumes | Notebook</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Kubernetes Volumes" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="DeepDive in Kubernetes Volumes" />
<meta property="og:description" content="DeepDive in Kubernetes Volumes" />
<link rel="canonical" href="https://hacstac.github.io/Notes/kubernetes/2020/10/08/Kubernetes-Volumes.html" />
<meta property="og:url" content="https://hacstac.github.io/Notes/kubernetes/2020/10/08/Kubernetes-Volumes.html" />
<meta property="og:site_name" content="Notebook" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-08T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"DeepDive in Kubernetes Volumes","url":"https://hacstac.github.io/Notes/kubernetes/2020/10/08/Kubernetes-Volumes.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hacstac.github.io/Notes/kubernetes/2020/10/08/Kubernetes-Volumes.html"},"headline":"Kubernetes Volumes","dateModified":"2020-10-08T00:00:00-05:00","datePublished":"2020-10-08T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Notes/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://hacstac.github.io/Notes/feed.xml" title="Notebook" /><link rel="shortcut icon" type="image/x-icon" href="/Notes/images/favicon.ico"><link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css">

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Notes/">Notebook</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Notes/about/">About Me</a><a class="page-link" href="/Notes/search/">Search</a><a class="page-link" href="/Notes/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Kubernetes Volumes</h1><p class="page-description">DeepDive in Kubernetes Volumes</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-10-08T00:00:00-05:00" itemprop="datePublished">
        Oct 8, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      18 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/Notes/categories/#Kubernetes">Kubernetes</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#10-kubernetes-volumes-attaching-disk-storage-to-containers">1.0 Kubernetes Volumes: Attaching disk storage to containers</a>
<ul>
<li class="toc-entry toc-h3"><a href="#11-why-we-need-persistant-volumes-with-pods">1.1 Why we need persistant volumes with pods</a></li>
<li class="toc-entry toc-h3"><a href="#12-volume-types">1.2 Volume Types</a>
<ul>
<li class="toc-entry toc-h4"><a href="#121-emptydir-volume">1.2.1 emptyDir Volume</a></li>
<li class="toc-entry toc-h4"><a href="#122-git-repo">1.2.2 Git Repo</a></li>
<li class="toc-entry toc-h4"><a href="#123-hostpath-volume">1.2.3 hostPath Volume</a></li>
<li class="toc-entry toc-h4"><a href="#124-persistent-storage">1.2.4 Persistent Storage</a></li>
<li class="toc-entry toc-h4"><a href="#125-nfs-storage">1.2.5 NFS Storage</a></li>
<li class="toc-entry toc-h4"><a href="#126-other-storage-technologies">1.2.6 Other Storage Technologies</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#13-deepdive-with-kubernetes-storage-technology">1.3 DeepDive with Kubernetes Storage Technology</a>
<ul>
<li class="toc-entry toc-h4"><a href="#131-creating-a-persistentvolume">1.3.1 Creating a PersistentVolume</a></li>
<li class="toc-entry toc-h4"><a href="#132-persistentvolumeclaim">1.3.2 PersistentVolumeClaim</a></li>
<li class="toc-entry toc-h4"><a href="#133-create-a-pod-using-pvc">1.3.3 Create a Pod using PVC</a></li>
<li class="toc-entry toc-h4"><a href="#134-recycling-persistentvolumes">1.3.4 Recycling PersistentVolumes</a></li>
<li class="toc-entry toc-h4"><a href="#135-dynamic-provisioning-of-persistentvolumes">1.3.5 Dynamic provisioning of PersistentVolumes</a></li>
</ul>
</li>
</ul>
</li>
</ul><hr>

<h2 id="10-kubernetes-volumes-attaching-disk-storage-to-containers">
<a class="anchor" href="#10-kubernetes-volumes-attaching-disk-storage-to-containers" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.0 Kubernetes Volumes: Attaching disk storage to containers</h2>

<p>Kubernetes volumes are a component of a pod and are thus defined in the pod’s specification much like containers. They aren’t a standalone Kubernetes object and cannot be created or deleted on their own. A volume is available to all containers in the pod, but it must be mounted in each container that needs to access it. In each container, you can mount the volume in any location of its filesystem</p>

<hr>

<h3 id="11-why-we-need-persistant-volumes-with-pods">
<a class="anchor" href="#11-why-we-need-persistant-volumes-with-pods" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.1 Why we need persistant volumes with pods</h3>

<p>In kubernetes each container in a pod has its own isolated filesystem, because the filesystem comes from the container’s image. Every new container starts off with the exact set of files that was added to the image at build time. Combine this with the fact that containers in a pod get restarted (either because the process died or because the liveness probe signaled to Kubernetes that the container wasn’t healthy anymore) and you’ll realize that the new container will not see anything that was written to the filesystem by the previous container, even though the newly started container runs in the same pod.</p>

<p>In certain scenarios you want the new container to continue where the last one finished, such as when restarting a process on a physical machine. You may not need (or want) the whole filesystem to be persisted, but you do want to preserve the directories that hold actual data.</p>

<p>Kubernetes provides this by defining storage volumes. They aren’t top-level resources like pods, but are instead defined as a part of a pod and share the same lifecycle as the pod. This means a volume is created when the pod is started and is destroyed when the pod is deleted. Because of this, a volume’s contents will persist across container restarts. After a container is restarted, the new container can see all the files that were written to the volume by the previous container. Also, if a pod contains multiple containers, the volume can be used by all of them at once.</p>

<hr>

<h3 id="12-volume-types">
<a class="anchor" href="#12-volume-types" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.2 Volume Types</h3>

<p>A wide variety of volume types is available. Several are generic, while others are specific to the actual storage technologies used underneath. Here’s a list of
several of the available volume types:</p>

<ul>
  <li>
<code class="language-plaintext highlighter-rouge">emptyDir</code> — A simple empty directory used for storing transient data.</li>
  <li>
<code class="language-plaintext highlighter-rouge">hostPath</code> — Used for mounting directories from the worker node’s filesystem
into the pod.</li>
  <li>
<code class="language-plaintext highlighter-rouge">gitRepo</code> — A volume initialized by checking out the contents of a Git repository.</li>
  <li>
<code class="language-plaintext highlighter-rouge">nfs</code> — An NFS share mounted into the pod.</li>
  <li>
<code class="language-plaintext highlighter-rouge">gcePersistentDisk</code> (Google Compute Engine Persistent Disk), <code class="language-plaintext highlighter-rouge">awsElasticBlockStore</code> (Amazon Web Services Elastic Block Store Volume), <code class="language-plaintext highlighter-rouge">azureDisk</code> (Microsoft Azure Disk Volume)—Used for mounting cloud provider-specific storage.</li>
  <li>
<code class="language-plaintext highlighter-rouge">cinder</code>, <code class="language-plaintext highlighter-rouge">cephfs</code>, <code class="language-plaintext highlighter-rouge">iscsi</code>, <code class="language-plaintext highlighter-rouge">flocker</code>, <code class="language-plaintext highlighter-rouge">glusterfs</code>, <code class="language-plaintext highlighter-rouge">quobyte</code>, <code class="language-plaintext highlighter-rouge">rbd</code>, <code class="language-plaintext highlighter-rouge">flexVolume</code>, <code class="language-plaintext highlighter-rouge">vsphere-Volume</code>, <code class="language-plaintext highlighter-rouge">photonPersistentDisk</code>, scaleIO—Used for mounting other types of network storage.</li>
  <li>
<code class="language-plaintext highlighter-rouge">configMap</code>, <code class="language-plaintext highlighter-rouge">secret</code>, <code class="language-plaintext highlighter-rouge">downwardAPI</code> — Special types of volumes used to expose certain Kubernetes resources and cluster information to the pod.</li>
  <li>
<code class="language-plaintext highlighter-rouge">persistentVolumeClaim</code> — A way to use a pre- or dynamically provisioned per`sistent storage.</li>
</ul>

<p>These volume types serve various purposes. You’ll learn about some of them in the
following sections. Special types of volumes ( secret, downwardAPI, configMap) are covered in the next phases, because they aren’t used for storing data, but for exposing Kubernetes metadata to apps running in the pod.</p>

<h4 id="121-emptydir-volume">
<a class="anchor" href="#121-emptydir-volume" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.2.1 emptyDir Volume</h4>

<p>The simplest volume type is the emptyDir volume. The app running inside the pod can then write any files it needs to it. Because the volume’s lifetime is tied to that of the pod, the volume’s contents are lost when the pod is deleted. An emptyDir volume is especially useful for sharing files between containers running in the same pod. But it can also be used by a single container for when a container needs to write data to disk temporarily, such as when performing a sort operation on a large dataset, which can’t fit into the available memory. The data could also be written to the container’s filesystem itself (remember the top read-write layer in a container?), but subtle differences exist between the two options. A container’s filesystem may not even be writable.</p>

<ul>
  <li>Ex : The pod contains two containers and a single volume that’s mounted in both of them, yet at different paths. When the html-generator container starts, it starts writing the output of the fortune command to the /var/htdocs/index.html file every 10 seconds. Because the volume is mounted at /var/htdocs, the index.html file is writ- ten to the volume instead of the container’s top layer. As soon as the web-server container starts, it starts serving whatever HTML files are in the /usr/share/nginx/html directory (this is the default directory Nginx serves files from). Because you mounted the volume in that exact location, Nginx will serve the index.html file written there by the container running the fortune loop. The end effect is that a client sending an HTTP request to the pod on port 80 will receive the current fortune message as the response.</li>
</ul>

<p>The emptyDir you used as the volume was created on the actual disk of the worker node hosting your pod, so its performance depends on the type of the node’s disks.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">---yaml</span>
apiVersion: v1
kind: Pod
metadata:
  name: fortune
spec:
  containers:
  - image: luksa/fortune
    name: html-generator
    volumeMounts:
    - name: html
      mountPath: /var/htdocs
  - image: nginx:alpine
    name: web-server
    volumeMounts:
    - name: html
      mountPath: /usr/share/nginx/html
      readOnly: <span class="nb">true
    </span>ports:
    - containerPort: 80
      protocol: TCP
    volumes:
    - name: html
    emptyDir: <span class="o">{}</span>
<span class="nt">---</span>

<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> ./fortune.yaml
<span class="nv">$ </span>kubectl port-forward fortune 8080:80

<span class="nv">$ </span>curl http://localhost:8080
Beware of a tall blond man with one black shoe.
<span class="c"># If you wait a few seconds and send another request, you should receive a different message.</span>

<span class="c"># To use emptyDir on tmpfs ( on ram instead of disk )</span>
volumes:
  - name: html
    emptyDir:
      medium: Memory
</code></pre></div></div>

<h4 id="122-git-repo">
<a class="anchor" href="#122-git-repo" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.2.2 Git Repo</h4>

<p>A gitRepo volume is basically an emptyDir volume that gets populated by cloning a
Git repository and checking out a specific revision when the pod is starting up (but
before its containers are created).</p>

<p>For example, you can use a Git repository to store static HTML files of your website
and create a pod containing a web server container and a gitRepo volume. Every time
the pod is created, it pulls the latest version of your website and starts serving it. The only drawback to this is that you need to delete the pod every time you push changes to the gitRepo and want to start serving the new version of the website.</p>

<p>Note: You need a github repo for the website/App</p>

<p>When you create the pod, the volume is first initialized as an empty directory and then the specified Git repository is cloned into it. If you hadn’t set the directory to . (dot), the repository would have been cloned into the kubia-website-example subdirectory, which isn’t what you want. You want the repo to be cloned into the root directory of your volume. Along with the repository, you also specified you want Kubernetes to check out whatever revision the master branch is pointing to at the time the volume is created.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">gitrepo-volume-pod</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">image</span><span class="pi">:</span> <span class="s">nginx:alpine</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">web-server</span>
    <span class="na">volumeMounts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">html</span>
      <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/usr/share/nginx/html</span>
      <span class="na">readOnly</span><span class="pi">:</span> <span class="no">true</span>
    <span class="na">ports</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">80</span>
      <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
  <span class="na">volumes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">html</span>
    <span class="na">gitRepo</span><span class="pi">:</span>
      <span class="na">repository</span><span class="pi">:</span> <span class="s">https://github.com/luksa/kubia-website-example.git</span>
      <span class="na">revision</span><span class="pi">:</span> <span class="s">master</span>
      <span class="na">directory</span><span class="pi">:</span> <span class="s">.</span>
</code></pre></div></div>

<p>To keep your app sync with github, you’ll need a sidecar container because git sync process shouldn’t run in the same container as the Nginx web server, but in a second container: a sidecar container. A sidecar container is a container that augments the operation of the main container of the pod. You add a sidecar to a pod so you can use an existing container image instead of cramming additional logic into the main app’s code, which would make it overly complex and less reusable. To find an existing container image, which keeps a local directory synchronized with a Git repository, go to Docker Hub and search for “git sync.” You’ll find many images that do that. Then use the image in a new container in the pod from the previous example, mount the pod’s existing gitRepo volume in the new container, and configure the Git sync container to keep the files in sync with your Git repo. If you set everything up correctly, you should see that the files the web server is serving are kept in sync with your GitHub repo.</p>

<p>A gitRepo volume, like the emptyDir volume, is basically a dedicated directory created specifically for, and used exclusively by, the pod that contains the volume. When the pod is deleted, the volume and its contents are deleted. Other types of volumes, however, don’t create a new directory, but instead mount an existing external directory into the pod’s container’s filesystem. The contents of that volume can survive multiple pod instantiations.</p>

<h4 id="123-hostpath-volume">
<a class="anchor" href="#123-hostpath-volume" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.2.3 hostPath Volume</h4>

<p>Most pods should be oblivious of their host node, so they shouldn’t access any files on the node’s filesystem. But certain system-level pods (remember, these will usually be managed by a DaemonSet) do need to either read the node’s files or use the node’s
filesystem to access the node’s devices through the filesystem. Kubernetes makes this
possible through a hostPath volume. A hostPath volume points to a specific file or directory on the node’s filesystem.</p>

<p>hostPath volumes are the first type of persistent storage we’re introducing, because both the gitRepo and emptyDir volumes’ contents get deleted when a pod is torn down, whereas a hostPath volume’s contents don’t. If a pod is deleted and the next pod uses a hostPath volume pointing to the same path on the host, the new pod will see whatever was left behind by the previous pod, but only if it’s scheduled to the same node as the first pod.</p>

<p>If you’re thinking of using a hostPath volume as the place to store a database’s data directory, think again. Because the volume’s contents are stored on a specific node’s filesystem, when the database pod gets rescheduled to another node, it will no longer see the data. This explains why it’s not a good idea to use a hostPath volume for regular pods, because it makes the pod sensitive to what node it’s scheduled to.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># To check existing pods using the hostPath or not</span>
<span class="nv">$ </span>kubectl describe pod kubia-x-x <span class="nt">--namespace</span> kube-system
</code></pre></div></div>

<h4 id="124-persistent-storage">
<a class="anchor" href="#124-persistent-storage" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.2.4 Persistent Storage</h4>

<p>When an application running in a pod needs to persist data to disk and have that same data available even when the pod is rescheduled to another node, you can’t use any of the volume types we’ve mentioned so far. Because this data needs to be accessible from any cluster node, it must be stored on some type of network-attached storage (NAS).</p>

<p>To learn about volumes that allow persisting data, you’ll create a pod that will run the MongoDB document-oriented NoSQL database. Running a database pod without a volume or with a non-persistent volume doesn’t make sense, except for testing purposes, so you’ll add an appropriate type of volume to the pod and mount it in the MongoDB container.</p>

<p>for example : we can use google kubernetes engine, where we can use GCE persistent disk as underlying storage mechanism.</p>

<p>Ex : Creating a GCE Persistent Disk in a pod volume</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Create a cluster</span>
<span class="nv">$ </span>gcloud compute disks create <span class="nt">--size</span><span class="o">=</span>1GB <span class="nt">--zone</span><span class="o">=</span>southeast-asia1-a mongodb

<span class="c"># Create a pod using gcePersistentDisk</span>
<span class="nt">---yaml</span>
apiVersion: v1
kind: Pod
metadata:
  name: mongodb
spec:
  volumes:
  - name: mongodb-data
    gcePersistentDisk:
    pdName: mongodb
    fsType: ext4
  containers:
  - image: mongo
    name: mongodb
    volumeMounts:
    - name: mongodb-data
      mountPath: /data/db
    ports:
    - containerPort: 27017
      protocol: TCP

<span class="c"># Spin up the pod</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> ./mongodb.yaml

<span class="c"># Entering the mongoDB Shell</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> mongodb mongo
</code></pre></div></div>

<p>If you delete the pod and recreate it. Mongo uses exact same data, because it uses the persistent disk. This is an example of GCE, If your Kubernetes cluster is running on Amazon’s AWS EC2, for example, you can use an awsElasticBlockStore volume to provide persistent storage for your pods. If your cluster runs on Microsoft Azure, you can use the azureFile or the azureDisk volume.</p>

<h4 id="125-nfs-storage">
<a class="anchor" href="#125-nfs-storage" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.2.5 NFS Storage</h4>

<p>If your cluster is running on your own set of servers, you have a vast array of other sup- ported options for mounting external storage inside your volume. For example, to mount a simple NFS share, you only need to specify the NFS server and the path exported by the server.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">volumes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">mongodb-data</span>
    <span class="na">nfs</span><span class="pi">:</span>
      <span class="na">server</span><span class="pi">:</span> <span class="s">11.151.150.124</span>
      <span class="na">path</span><span class="pi">:</span> <span class="s">/some/path</span>
</code></pre></div></div>

<h4 id="126-other-storage-technologies">
<a class="anchor" href="#126-other-storage-technologies" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.2.6 Other Storage Technologies</h4>

<p>Other supported options include iscsi for mounting an ISCSI disk resource, glusterfs for a GlusterFS mount, rbd for a RADOS Block Device, flexVolume , cinder, cephfs, flocker, fc (Fibre Channel), and others. You don’t need to know all of them if you’re not using them. They’re mentioned here to show you that Kubernetes supports a broad range of storage technologies and you can use whichever you prefer and are used to.</p>

<p>To see details on what properties you need to set for each of these volume types,
you can either turn to the Kubernetes API definitions in the Kubernetes API refer-
ence or look up the information through kubectl explain.</p>

<hr>

<h3 id="13-deepdive-with-kubernetes-storage-technology">
<a class="anchor" href="#13-deepdive-with-kubernetes-storage-technology" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.3 DeepDive with Kubernetes Storage Technology</h3>

<p>To enable apps to request storage in a Kubernetes cluster without having to deal with infrastructure specifics, two new resources were introduced. They are PersistentVolumes and PersistentVolumeClaims. The names may be a bit misleading, because as you’ve seen in the previous few sections, even regular Kubernetes volumes can be used to store persistent data.</p>

<p>Using a PersistentVolume inside a pod is a little more complex than using a regular
pod volume, so let’s illustrate how pods, PersistentVolumeClaims, PersistentVolumes,
and the actual underlying storage relate to each other.</p>

<p><img src="https://s3.ap-south-1.amazonaws.com/akash.r/Devops_Notes_screenshots/Kubernetes/PersistentStorage.png" alt="PersistentVolume"></p>

<p><strong>Explaination</strong>: Instead of the developer adding a technology-specific volume to their pod, it’s the cluster administrator who sets up the underlying storage and then registers it in Kubernetes by creating a PersistentVolume resource through the Kubernetes API server. When creating the PersistentVolume, the admin specifies its size and the access modes it supports. When a cluster user needs to use persistent storage in one of their pods, they first create a PersistentVolumeClaim manifest, specifying the minimum size and the access mode they require. The user then submits the PersistentVolumeClaim manifest to the Kubernetes API server, and Kubernetes finds the appropriate PersistentVolume and binds the volume to the claim. The PersistentVolumeClaim can then be used as one of the volumes inside a pod. Other users cannot use the same PersistentVolume until it has been released by deleting the bound PersistentVolumeClaim.</p>

<h4 id="131-creating-a-persistentvolume">
<a class="anchor" href="#131-creating-a-persistentvolume" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.3.1 Creating a PersistentVolume</h4>

<p>When creating a PersistentVolume, the administrator needs to tell Kubernetes what its capacity is and whether it can be read from and/or written to by a single node or by multiple nodes at the same time. They also need to tell Kubernetes what to do with the PersistentVolume when it’s released (when the PersistentVolumeClaim it’s bound to is deleted. And last, but certainly not least, they need to specify the type, location, and other properties of the actual storage this PersistentVolume is backed by.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolume</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">mongodb-pv</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">capacity</span><span class="pi">:</span>
    <span class="na">storage</span><span class="pi">:</span> <span class="s">1Gi</span>
  <span class="na">accessModes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="pi">-</span> <span class="s">ReadOnlyMany</span>
  <span class="na">persistentVolumeReclaimPolicy</span><span class="pi">:</span> <span class="s">Retain</span>
  <span class="na">gcePersistentDisk</span><span class="pi">:</span>
    <span class="na">pdName</span><span class="pi">:</span> <span class="s">monodb</span>
    <span class="na">fsType</span><span class="pi">:</span> <span class="s">ext4</span>
</code></pre></div></div>

<p>Note: PersistentVolumes don’t belong to any namespaces</p>

<h4 id="132-persistentvolumeclaim">
<a class="anchor" href="#132-persistentvolumeclaim" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.3.2 PersistentVolumeClaim</h4>

<p>Now let’s lay down our admin hats and put our developer hats back on. Say you need to deploy a pod that requires persistent storage. You’ll use the PersistentVolume you created earlier. But you can’t use it directly in the pod. You need to claim it first. Claiming a PersistentVolume is a completely separate process from creating a pod, because you want the same PersistentVolumeClaim to stay available even if the pod is rescheduled (remember, rescheduling means the previous pod is deleted and a new one is created).</p>

<p>As soon as you create the claim, Kubernetes finds the appropriate PersistentVolume and binds it to the claim. The PersistentVolume’s capacity must be large enough to accommodate what the claim requests. Additionally, the volume’s access modes must include the access modes requested by the claim. In your case, the claim requests 1 GiB of storage and a ReadWriteOnce access mode. The PersistentVolume you created earlier matches those two requirements so it is bound to your claim.</p>

<p>The claim is shown as Bound to PersistentVolume mongodb-pv. Note the abbreviations
used for the access modes:</p>

<ul>
  <li>RWO—ReadWriteOnce—Only a single node can mount the volume for reading and writing.</li>
  <li>ROX—ReadOnlyMany—Multiple nodes can mount the volume for reading.</li>
  <li>RWX—ReadWriteMany—Multiple nodes can mount the volume for both reading and writing.</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolumeClaim</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">mongodb-pvc</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">resources</span><span class="pi">:</span>
    <span class="na">requests</span><span class="pi">:</span>
      <span class="na">storage</span><span class="pi">:</span> <span class="s">1Gi</span>
  <span class="na">accessModes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="s">storageClassName:""</span>
</code></pre></div></div>

<h4 id="133-create-a-pod-using-pvc">
<a class="anchor" href="#133-create-a-pod-using-pvc" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.3.3 Create a Pod using PVC</h4>

<p>The PersistentVolume is now yours to use. Nobody else can claim the same volume
until you release it. To use it inside a pod, you need to reference the Persistent-
VolumeClaim by name inside the pod’s volume (yes, the PersistentVolumeClaim, not
the PersistentVolume directly!).</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">mongodb</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">image</span><span class="pi">:</span> <span class="s">mongo</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">mongodb</span>
    <span class="na">volumeMounts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">mongodb-data</span>
      <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/data/db</span>
    <span class="na">ports</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">27017</span>
      <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
  <span class="na">volumes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">mongodb-data</span>
    <span class="na">persistentVolumeClaim</span><span class="pi">:</span>
      <span class="na">claimName</span><span class="pi">:</span> <span class="s">mongodb-pvc</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># List out the PersistentVolumes</span>
<span class="nv">$ </span>kubectl get pv

<span class="c"># List out the PersistentVolumesClaims</span>
<span class="nv">$ </span>kubectl get pvc
</code></pre></div></div>

<h4 id="134-recycling-persistentvolumes">
<a class="anchor" href="#134-recycling-persistentvolumes" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.3.4 Recycling PersistentVolumes</h4>

<p>If you delete the pod and the pvc and create a new PVC on it, It will show a pending state because The STATUS column shows the PersistentVolume as Released, not Available like before. Because you’ve already used the volume, it may contain data and shouldn’t be bound to a completely new claim without giving the cluster admin a chance to clean it up. Without this, a new pod using the same PersistentVolume could read the data stored there by the previous pod, even if the claim and pod were created in a different namespace (and thus likely belong to a different cluster tenant).</p>

<p>To reclaim the pv, there are two policies exist: Recycle and Delete. The first one deletes
the volume’s contents and makes the volume available to be claimed again. This way, the PersistentVolume can be reused multiple times by different PersistentVolumeClaims and different pods. The Delete policy, on the other hand, deletes the underlying storage. Note that the Recycle option is currently not available for GCE Persistent Disks.</p>

<p>A PersistentVolume only supports the Retain or Delete policies. Other PersistentVolume types may or may not support each of these options, so before creating your own PersistentVolume, be sure to check what reclaim policies are supported for the specific underlying storage you’ll use in the volume.</p>

<h4 id="135-dynamic-provisioning-of-persistentvolumes">
<a class="anchor" href="#135-dynamic-provisioning-of-persistentvolumes" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.3.5 Dynamic provisioning of PersistentVolumes</h4>

<p>You’ve seen how using PersistentVolumes and PersistentVolumeClaims makes it easy to obtain persistent storage without the developer having to deal with the actual stor- age technology used underneath. But this still requires a cluster administrator to pro- vision the actual storage up front. Luckily, Kubernetes can also perform this job automatically through dynamic provisioning of PersistentVolumes. The cluster admin, instead of creating PersistentVolumes, can deploy a Persistent- Volume provisioner and define one or more StorageClass objects to let users choose what type of PersistentVolume they want. The users can refer to the StorageClass in their PersistentVolumeClaims and the provisioner will take that into account when provisioning the persistent storage.</p>

<p><img src="https://s3.ap-south-1.amazonaws.com/akash.r/Devops_Notes_screenshots/Kubernetes/dynamicPV.png" alt="dynamicPeristentVolume"></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">---storageClass</span>.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast
provisioner: kubernetes.io/gce-pd
parameters:
  <span class="nb">type</span>: pd-ssd
  zone: asia-southest1-b

<span class="nt">---PersistentVolume</span>.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mongodb-pvc
spec:
  storageClassName: fast
  resources:
    requests:
      storage: 100Mi
  accessModes:
    - ReadWriteOnce

<span class="nv">$ </span>kubectl get sc
NAME                     TYPE
fast                     kubernetes.io/gce-pd
standard <span class="o">(</span>default<span class="o">)</span>       kubernetes.io/gce-pd

<span class="nv">$ </span>kubectl get pv
NAME          CAPACITY      ACCESSMODES      RECLAIMPOLICY      STATUS      STORAGECLASS
mongodb-pv    1Gi           RWO,ROX          Retain             Released
pvc-1e6bc048  1Gi           RWO              Delete             Bound       fast

<span class="nv">$ </span>kubectl get pvc mongodb-pvc
NAME         STATUS      VOLUME       CAPACITY      ACCESSMODES      STORAGECLASS
mongodb-pvc  Bound      pvc-1e6bc048  1Gi           RWO              fast
</code></pre></div></div>

<hr>

  </div><a class="u-url" href="/Notes/kubernetes/2020/10/08/Kubernetes-Volumes.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Notes/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Notes/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Notes/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A Daily Notebook for @Akash</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/AkashRajvanshi" title="AkashRajvanshi"><svg class="svg-icon grey"><use xlink:href="/Notes/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/Akash_Rajvanshi" title="Akash_Rajvanshi"><svg class="svg-icon grey"><use xlink:href="/Notes/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
