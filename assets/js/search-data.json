{
  
    
        "post0": {
            "title": "Docker Hard Parts",
            "content": "7.0 Building Images automatically with DockerFiles . . 7.1 Instructions . .dockerignore | FROM Sets the Base Image for subsequent instructions. | MAINTAINER (deprecated - use LABEL instead) Set the Author field of the generated images. | RUN execute any commands in a new layer on top of the current image and commit the results. | CMD provide defaults for an executing container. | EXPOSE informs Docker that the container listens on the specified network ports at runtime. NOTE: does not actually make ports accessible. | ENV sets environment variable. | ADD copies new files, directories or remote file to container. Invalidates caches. Avoid ADD and use COPY instead. | COPY copies new files or directories to container. By default this copies as root regardless of the USER/WORKDIR settings. Use --chown=&lt;user&gt;:&lt;group&gt; to give ownership to another user/group. (Same for ADD.) | ENTRYPOINT configures a container that will run as an executable. | VOLUME creates a mount point for externally mounted volumes or other containers.* USER sets the user name for following RUN / CMD / ENTRYPOINT commands. | WORKDIR sets the working directory. | ARG defines a build-time variable. | ONBUILD adds a trigger instruction when the image is used as the base for another build. | STOPSIGNAL sets the system call signal that will be sent to the container to exit. | LABEL apply key/value metadata to your images, containers, or daemons. | . NOTE : If your running dangerous commands ( add a logic that it fails if your shell is outside docker ) . # Shell script fails if it’s run outside a container #!/bin/bash if ! [ -f /.dockerenv ] then echo &#39;Not in a Docker container, exiting.&#39; exit 1 fi . . 7.2 Getting Practical . 7.2.1 Packaging Git with Dockerfile . # Create a file name Dockerfile FROM ubuntu:latest LABEL maintainer=&quot;dia@allingeek.com&quot; RUN apt-get update &amp;&amp; apt-get install -y git ENTRYPOINT [&quot;git&quot;] # Instantly Create Dockerfile Images $ docker build -t htop - &lt;&lt; EOF FROM alpine RUN apk --no-cache add htop EOF $ docker image build --tage ubuntu-git:auto . FROM ubuntu:latest — Tells Docker to start from the latest Ubuntu image just as you did when creating the image manually. LABEL maintainer — Sets the maintainer name and email for the image. Provid- ing this information helps people know whom to contact if there’s a problem with the image. This was accomplished earlier when you invoked commit. RUN apt-get update &amp;&amp; apt-get install -y git — Tells the builder to run the provided commands to install Git. ENTRYPOINT [&quot;git&quot;] — Sets the entrypoint for the image to git. # --file or -f will read from diff file like &#39;BuildScript or anything&#39; # --quiet or -q will run in quiet mode . . 7.2.2 Dockerignore . .dockerignore file will help us to exclude some files to add to the image during the build | CLI modifies the context to exclude files and directories that match patterns in it. This helps to avoid unnecessarily sending large or sensitive files and directories to the daemon and potentially adding them to images using ADD or COPY. | . . 7.2.3 File System Instructions . - COPY : Will copy files from the filesystem where the image is being built. - VOLUME : Same as --volume flag ( bound mount volume ) - CMD : This is a closely related to ENTRYPOINT - ADD : This operates similarly to the COPY instruction with two imp differences: - fetch remote sources files if a Url is specified - Extract the files of any source determined to be an archive file - ONBUILD : This instruction let the other instructions to execute ( if resulting image is used as base img for another build ) # Example # ADD : We can ADD large no of files to a container without any problem # Docker will unpack tarfiles of most standard types (.gz, .bz2, .xz, .tar). # some.tar FROM Debian RUN mkdir -p /opt/libeatmydata ADD some.tar.gz /opt/libeatmydata/ RUN ls -lRt /opt/libeatmydata # ONBUILD : Use the ONBUILD command to automate and encapsulate the building of an image. # GO Example ( Outyet : Simple Go App ) $ git clone https://github.com/golang/example $ cd example/outyet $ docker build -t outyet . $ docker run --publish 8080:8080 --name outyet1 -d outyet With ONBUILD FROM golang:onbuild EXPOSE 8080 golang:onbuild Dockerfile FROM golang:1.7 RUN mkdir -p /go/src/app WORKDIR /go/src/app CMD [&quot;go-wrapper&quot;, &quot;run&quot;] ONBUILD COPY . /go/src/app ONBUILD RUN go-wrapper download ONBUILD RUN go-wrapper install The result of this technique is that you have an easy way to build an image that only contains the code required to run it, and no more. There are also other examples of ONBUILD exists : node:onbuild , python:onbuild # ENTRYPOINT : Sets the entrypoint for the image # Basic Shell Script for clean logs #!/bin/bash echo &quot;Cleaning logs over $1 days old&quot; find /log_dir -ctime &quot;$1&quot; -name &#39;*log&#39; -exec rm {} ; # Create a DockerFile ( Create a container with clean_log script ) FROM ubuntu:17.04 ADD clean_log /usr/bin/clean_log RUN chmod +x /usr/bin/clean_log ENTRYPOINT [&quot;/usr/bin/clean_log&quot;] CMD [&quot;7&quot;] $ docker build -t log-cleaner . $ docker run -v /var/log/myapplogs:/log_dir log-cleaner 365 # Clean The logs of over a year ( default 7 days if no arg given ) . . 7.2.4 Create a Maintainable Dockerfiles . - ARG : arg defines a variable thta users can provide to docker when building and a image. Ex: Dockerfile ARG VERSION=unknown ENV VERSION=&quot;${VERSION}&quot; LABEL base.version=&quot;${VERSION}&quot; $ version=0.6; docker image build -t dockerinaction/mailer-base:${version} -f mailer-base.df --build-arg VERSION=${version} . $ docker image inspect --format &#39;&#39; dockerinaction/mailer-base:0.6 { &quot;base.name&quot;: &quot;Mailer Archetype&quot;, &quot;base.version&quot;: &quot;0.6&quot;, &quot;maintainer&quot;: &quot;dia@allingeek.com&quot; } . . 7.2.5 Init System for Docker . Most Popular init systems are : runit, tini, BusyBox init, Supervisord, and DAEMON | By Default docker comes with tini init system | . $ docker container run -it --init alpine:3.6 nc -l -p 3000 # Docker ran /dev/init -- nc -l -p 3000 inside the container instead of just nc . . 7.2.6 Health Check In Docker . - There are two ways to specify the health check command: 1. Use a HEALTHCHECK instruction when defining the image 2. On the command-line when running a container 1. This is a 1st Mothed : It is used when we define an Image $ FROM nginx:1.13-alpine HEALTHCHECK --interval=5s --retries=2 CMD nc -vz -w 2 localhost 80 || exit 1 $ docker ps --format &#39;table t t&#39; NAMES IMAGE STATUS healthcheck_ex dockerinaction/healthcheck Up 3 minutes (healthy) # Exit Status Codes - 0: success—The container is healthy and ready for use. - 1: unhealthy—The container is not working correctly. - 2: reserved—Do not use this exit code. 2. Command-line Method $ docker container run --name=healthcheck_ex -d --health-cmd=&#39;nc -vz -w 2 localhost 80 || exit 1&#39; nginx:1.13-alpine . . 7.2.7 Hardening Application Images . - There are Three Methods to hardended the images 1. We can enforce that our images are built from a specific image. 2. we can make sure that regardless of how containers are built from our image, they will have a sensible default user. 3. we should eliminate a common path for root user escalation from programs with setuid or setgid attributes set. 1. Content Addressable Images identifiers ( CAIID ) # Build Images using authentic digest : that digest is known as CAIID # So now how many images we build from these they are authentic. docker pull debian:stable stable: Pulling from library/debian 31c6765cabf1: Pull complete Digest: sha256:6aedee3ef827... # Dockerfile: FROM debian@sha256:6aedee3ef827... ... 2. Create a User &amp; groups $ RUN groupadd -r postgres &amp;&amp; useradd -r -g postgres postgres 3. SUID &amp; GUID $ FROM ubuntu:latest # Set the SUID bit on whoami RUN chmod u+s /usr/bin/whoami # Create an example user and set it as the default RUN adduser --system --no-create-home --disabled-password --disabled-login --shell /bin/sh example USER example # Set the default to compare the container user and # the effective user for whoami CMD printf &quot;Container running as: %s n&quot; $(id -u -n) &amp;&amp; printf &quot;Effectively running whoami as: %s n&quot; $(whoami) Output Container running as: example Effectively running whoami as: root The output of the default command shows that even though you’ve executed the whoami command as the example user, it’s running from the context of the root user. . . 7.2.8 Complete Story of Cache . # --no-cache will downlaod fresh containers from source. it will not use the cache files # Example $ docker build --no-cache . # Busting the Cache # we need this because some time our image build takes so much time. so we need cache up to a certain point. # Method 1 (cheat) : Add a benign comment after the command to invalidate the cache. This works because Docker treats the non-whitespace change to theline as though it were a new command, so the cached layer is not re-used. CMD [&quot;npm&quot;,&quot;start&quot;] #bust the cache # Method 2 ( using ARG ) Use the ARG directive in your Dockerfile to enable surgical cache-busting. If this ARG variable isset to a value never used before on your host, the cache will be busted from that point. WORKDIR todo ARG CACHEBUST=no RUN npm install $ docker build --build-arg CACHEBUST=${RANDOM} . $ echo ${RANDOM} 19856 $ echo ${RANDOM} 26429 # If not using Bash $ docker build --build-arg CACHEBUST=$(date +%s) . # Method 3 ( Using ADD ) There are two useful features of ADD that you can use to your advantage in this context: it caches the contents of the file it refers to, and it can take a network resource as an argument. # Git Repo Example It means if repo is not changed it uses cache or if git repo is changed it rebuild the image from scratch. But it will vary from resources type to resource type. we can take help of Github API here : It has URLs foreach repository that return JSON for the most recent commits. When a new commit ismade, the content of the response changes. FROM ubuntu:16.04 ADD https://api.github.com/repos/nodejs/node/commits /dev/null RUN git clone https://github.com/nodejs/node . . 7.2.9 Flattening Images . # This is imp because images can reveal the imp information Example : # create a docker file : It has sensitive information FROM debian RUN echo &quot;My Big Secret&quot; &gt;&gt; /tmp/secret_key RUN cat /tmp/secret_key RUN rm /tmp/secret_key $ docker build -t secret . # But now problem arise $ docker history secret ... 5e39caf7560f 3 days ago /bin/sh -c echo &quot;My Big Secret&quot; &gt;&gt; /tmp/se 14 B ... $ docker run 5b376ff3d7cd cat /tmp/secret_key My Big Secret But if someone could download this image from public repo and insect the history &amp; run thi command : It reveal the secret. # To get rid of this type of problem : we need to remove intermediate layering # we need to export the image as a trivially run container and then re-import and tag the resulting image: $ docker run -d secret /bin/true - new_id # Runs a docker export, taking a conatiner iD as arg and outgoing a tar file of fs contents. # This is piped to docker import which takes tar file and create a new image. $ docker export new_id | docker import - new_secret $ docker history new_secret . . 7.3 Refer . Examples | Best practices for writing Dockerfiles | Michael Crosby has some more Dockerfiles best practices / take 2. | Building Good Docker Images / Building Better Docker Images | Managing Container Configuration with Metadata | How to write excellent Dockerfiles | . . . 8.0 Registry &amp; Repository . . A repository is a hosted collection of tagged images that together create the file system for a container. . A registry is a host – a server that stores repositories and provides an HTTP API for managing the uploading and downloading of repositories. . 8.1 Enviornment . docker login to login to a registry. | docker logout to logout from a registry. | docker search searches registry for image. | docker pull pulls an image from registry to local machine. | docker push pushes an image to the registry from local machine. | . NOTE : Refer Chapter 9 of Docker in Action : Public and private software distribution ( This Cover’s Every Basic detail about Registry &amp; Repository ) . 8.2 Setup Local Docker Registry . # To start a registry on local Network $ docker run -d -p 5000:5000 -v $HOME/registry:/var/lib/registry registry:2 # This command makes the registry available on port 5000 of the Docker host(-p 5000:5000). With the -v flag, it makes the registry folder on your host(/var/lib/registry) available in the container as $HOME/registry. The registry’s fileswill therefore be stored on the host in the /var/lib/registry folder. # HOSTNAME is the hostname or IP address of your new reg-istry server # we also use --insecure-registry ( We know our local network is secure :) [Docker will only allow you to pull from registries with a signedHTTPS certificate.] ) # Push the image to the registry $ docker push HOSTNAME:5000/image:tag. . . . 9.0 Docker Compose . Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application’s services. Then, with a single command, you create and start all the services from your configuration. To learn more about all the features of Compose, see the list of features. . The standard filename for Compose files is docker-compose.yml. . 9.1 YAML Basics . A YAML document can include a comment at the end of any line. Com￾ments are marked by a space followed by a hash sign ( #). Any characters that follow until the end of the line are ignored by the parser. | YAML uses three types of data and two styles of describing that data, block and flow. Flow collections are specified similarly to collection literals in JavaScript and other languages. For example, the following is a list of strings in the flow style: [&quot;PersonA&quot;,&quot;PersonB&quot;] | The block style is more common and will be used in this primer except where noted. The three types of data are maps, lists, and scalar values. Maps are defined by a set of unique properties in the form of key/value pairs that are delimited by a colon and space (: ). | Scaler Values : Scaler String image: &quot;alpine&quot; , Scaler Command : command: echo hello world | Scaler Rules : Must not be empty, | Must not contain leading or trailing whitespace characters | Must not begin with an indicator character (for example, - or :) in places where doing so would cause an ambiguity. | Must never contain character combinations using a colon (:) and hash sign (#) | | Lists (or block sequences) are series of nodes in which each element is denoted by a leading hyphen (-) indicator. For example: - item 1 - item 2 - item 3 - # an empty item - item 4 | . | . | Indentation Rules : YAML uses indentation to indicate content scope. Scope determines which block each element belongs to. There are a few rules: Only spaces can be used for indentation. | The amount of indentation does not matter as long as – All peer elements (in the same scope) have the same amount of indentation. – Any child elements are further indented. | . | . These documents are equivalent: . top-level: second-level: # three spaces third-level: # two more spaces - &quot;list item&quot; # single additional indent on items in this list another-third-level: # a third-level peer with the same two spaces fourth-level: &quot;string scalar&quot; # 6 more spaces another-second-level: # a 2nd level peer with three spaces - a list item # list items in this scope have # 15 total leading spaces - a peer item # A peer list item with a gap in the list # every scope level adds exactly 1 space top-level: second-level: third-level: - &quot;list item&quot; another-third-level: fourth-level: &quot;string scalar&quot; another-second-level: - a list item - a peer item . 9.2 Docker Compose Basics . By using the following command you can start up your application: . # first install docker-compose on your system (eg: Ubuntu ) $ sudo apt install docker-compose $ docker-compose -f &lt;docker-compose-file&gt; up . You can also run docker-compose in detached mode using -d flag, then you can stop it whenever needed by the following command: . docker-compose stop . You can bring everything down, removing the containers entirely, with the down command. Pass --volumes to also remove the data volume. . Let understand Docker compose with an Example : . 9.2.1 Example yml . # wikijs.yml version: &#39;2&#39; services: db: image: postgres:11-alpine environment: POSTGRES_DB: wiki POSTGRES_PASSWORD: wikijsrocks POSTGRES_USER: wikijs logging: driver: &quot;none&quot; restart: unless-stopped volumes: - db-data:/var/lib/postgresql/data wiki: image: requarks/wiki:2 depends_on: - db environment: DB_TYPE: postgres DB_HOST: db DB_PORT: 5432 DB_USER: wikijs DB_PASS: wikijsrocks DB_NAME: wiki restart: unless-stopped ports: - &quot;80:3000&quot; volumes: db-data: # we can create a docker stack with this yml file ( it established a wikijs and postgresql db ) $ docker stack deploy -c wikijs.yml wikijs # if we use docker swarn or Kubernetes we can create a replicas of this images into 3 diff servers -- deploy: replicas: 3 -- # add this to end of yml and again deploy it. It will update the container # To Check The State of stack $ docker stack ps --format &#39; t&#39; wikijs # To remove a service from stack ( like limit the replicas from 3 to 2 ) $ docker stack deploy -c wikijs.yml --prune wikijs We Need To use Prue Here : Because without Prune it will not completely remove services which causes problmes ( like for Instead of using postgressql we want to use a mysql so if we updated our stack yml file and deploy it. it will add mysql db but doesn&#39;t remove postgres containers so to remove postgres we use prune ) The --prune flag will clean up any resource in the stack that isn’t explicitly referenced in the Compose file used for the deploy operation. # Prune The new [Data Management Commands](https://github.com/docker/docker/pull/26108) have landed as of Docker 1.13: * `docker system prune` * `docker volume prune` * `docker network prune` * `docker container prune` * `docker image prune` Note : There is a problem here everytime a container replaced docker will create a new volume space for container and its replicas. This would cause problems in a real-world system. So, to get rid of this EX: volumes: pgdata: # empty definition uses volume defaults services: postgres: image: dockerinaction/postgres:11-alpine volumes: - type: volume source: pgdata # The named volume above target: /var/lib/postgresql/data environment: POSTGRES_PASSWORD: example The file defines a volume named pgdata, and the postgres service mounts that volume at /var/lib/postgresql/data. That location is where the Postgre￾SQL software will store any database schema or data. Inspect $ docker stack deploy -c databases.yml --prune my-databases $ docker volume ls DRIVER VOLUME NAME local my-databases_pgdata $ docker service remove my-databases_postgres Then restore the service by using the Compose file: $ docker stack deploy -c databases.yml --prune my-databases . . . 10.0 DevOps Operations With Docker . . 10.1 Convert Your Virtual Box VM To Docker Container . # Process : VM FILE (.vdi or anything) =&gt; TAR =&gt; Import TAR as an Image in Docker. $ sudo apt install qemu-utils # Identify the path to your VM disk image. ( Stop the VM ) # Sets up a variable pointingto your VM disk image. $ VMDISK=&quot;$HOME/VirtualBox VMs/myvm/myvm.vdi&quot; # Initializes a kernelmodule requiredby qemu-nbd $ sudo modprobe nbd # Connects the VM disk to a virtual device node $ sudo qemu-nbd -c /dev/nbd0 -r $VMDISK3((CO1-3)) # Lists the partition numbers available to mount on this disk $ ls /dev/nbd0p* /dev/nbd0p1 /dev/nbd0p2 # Mounts the selected partition at /mnt with qemu-nbd $ sudo mount /dev/nbd0p2 /mnt # Creates a TAR filecalled img.tar from /mnt $ sudo tar cf img.tar -C /mnt . # Unmounts and cleans up after qemu-nbd $ sudo umount /mnt &amp;&amp; sudo qemu-nbd -d /dev/nbd0 # Dockerfile FROM scratch ADD img.tar / $ docker build . . . 10.2 Host Like Container . Containers are not virtual machines—there are significant differences—and pretending there aren’t can cause confusion and issues down the line. . Differences between VMs and Docker containers: Docker is application-oriented, whereas VMs are operating-system oriented. | Docker containers share an operating system with other Docker containers. Incontrast, VMs each have their own operating system managed by a hypervisor. | Docker containers are designed to run one principal process, not manage mul-tiple sets of processes. | . | . docker run -d phusion/baseimage [ This Image designed to run multiple processes.] docker exec -i -t container_ID /bin/bash ps -ef [ It starts (cron, sshd, and syslog). It Much like a host. ] . . 10.3 Running GUI in Containers . Process : Create an image with your user credentials and the program, and bind mount your Xserver to it. Note : another method is to setup VNC server on container . # Dockerfile for setting up firefox on container FROM ubuntu:14.04 RUN apt-get update RUN apt-get install -y firefox RUN groupadd -g GID USERNAME RUN useradd -d /home/USERNAME -s /bin/bash -m USERNAME -u UID -g GID USER USERNAME ENV HOME /home/USERNAME CMD /usr/bin/firefox $ docker build -t gui . $ docker run -v /tmp/.X11-unix:/tmp/.X11-unix -h $HOSTNAME -v $HOME/.Xauthority:/home/$USER/.Xauthority -e DISPLAY=$DISPLAY gui # It will popup firefox ( which runs on container ) . . 10.4 Using Docker Machine to Provision Docker Hosts . Docker-machine is a tool just like a vagrant. EX: we can setup VM with virtualBox with docker command. walkthrough: . # Install Docker Machine on Linux $ curl -L https://github.com/docker/machine/releases/download/v0.16.2/docker-machine-`uname -s`-`uname -m` &gt;/tmp/docker-machine &amp;&amp; chmod +x /tmp/docker-machine &amp;&amp; sudo cp /tmp/docker-machine /usr/local/bin/docker-machine # Create a VM by docker daemon on Oracle Virtual Box $ docker-machine create --driver virtualbox host1 # Run this command to set the DOCKER_HOST environment variable, which sets the default host that Docker commands will be run on $ docker-machine env host1 $ eval $(docker-machine env host1) # we can direct to VM $ docker-machine ssh host1 Commands of Docker-Machine: create : Creates a new Machine ls : List Machines stop : Stop Machines start : Start Machines restart : Restart Machines rm : Destroys the machine inspect : Returns a JSON representation of the machine’s metadata config : Return the config of machine ip : Returns the IP address of the machine url : Returns a URL for the Docker daemon on the machine upgrade : Upgrades the Docker version on the host to the latest . . 10.5 Build Images using a Chef Solo . Chef : It is a configuration Management Tool ( using this can reduce the amount of work required to configure Images ) . Here we setup hello world apache website ( Example ). | . # Need a working code $ git clone https://github.com/docker-in-practice/docker-chef-solo-example.git # All the working code in there $ cd into it ( there is a Dockerfile and some other files and folders ( chef recepies etc ) $ docker build -t chef-example . $ docker run -it -p 8080:80 chef-example # This is a one time written code we can anywhere to deploy a website ( in such a small steps ) . . 10.6 CI Operations With Docker . CI : Continious Integration . . 10.6.1 Steps . Check out a clean copy of the source code defining the image and build scripts so the origin and process used to build the image is known. | Retrieve or generate artifacts that will be included in the image, such as the application package and runtime libraries. | Build the image by using a Dockerfile. | Verify that the image is structured and functions as intended. | (Optional) Verify that the image does not contain known vulnerabilities. | Tag the image so that it can be consumed easily. | Publish the image to a registry or another distribution channel. | . 10.6.2 Method 1 : Builds a Image Using DockerHub Workflow ( Test and Push Images ) . # For this you will Git Repo and docker Hub Repo # Link Docker Hub to to git repo ( it take code from git repo and compile and create a desired Image ( like other ci tools do ) # wait for the docker hub to build to complete # Remember this is a basic solution . 10.6.3 Method 2 : Setting up a package cache for faster Builds . While building the images it will take caches instead of download everytime from internet. . # We are using squid Proxy Here $ sudo apt-get install squid-deb-proxy $ check for port 8000 $ create a Docker File using a apt proxy FROM debian RUN apt-get update -y &amp;&amp; apt-get install net-tools RUN echo &quot;Acquire::http::Proxy &quot;http://$( route -n | awk &#39;/^0.0.0.0/ {print $2}&#39; ):8000 &quot;;&quot; &gt; /etc/apt/apt.conf.d/30proxy RUN echo &quot;Acquire::http::Proxy::ppa.launchpad.net DIRECT;&quot; &gt;&gt; /etc/apt/apt.conf.d/30proxy CMD [&quot;/bin/bash&quot;] This will cache all the webpages and apt package we downlaod after running this container : if again download them they will be download in miliseconds . 10.6.3 Method 3 : Running the Jenkins Master Withing the Docker Container . Portable Jenkins Server . # download git clone https://github.com/docker-in-practice/jenkins.git. # Put your required plugins in jenkins_plugins.txt Dockerfile FROM jenkins COPY jenkins_plugins.txt /tmp/jenkins_plugins.txt RUN /usr/local/bin/plugins.sh /tmp/jenkins_plugins.txt USER root RUN rm /tmp/jenkins_plugins.txt RUN groupadd -g 999 docker RUN addgroup -a jenkins docker USER jenkins $ docker build -t jenkins . $ docker run --name jenkins -p 8080:8080 -p 50000:50000 -v /var/run/docker.sock:/var/run/docker.sock -v /tmp:/var/jenkins_home -d jenkins # go to localhost:8080 : Copy master password from logs # Reliably Upgrade a Jenkins Server Dockerfile FROM docker ADD jenkins_updater.sh /jenkins_updater.sh RUN chmod +x /jenkins_updater.sh ENTRYPOINT /jenkins_updater.sh Shell script to backup and restart Jenkins #!/bin/sh set -e set -x if ! docker pull jenkins | grep up.to.date then docker stop jenkins docker rename jenkins jenkins.bak.$(date +%Y%m%d%H%M) cp -r /var/docker/mounts/jenkins_home /var/docker/mounts/jenkins_home.bak.$(date +%Y%m%d%H%M) docker run -d --restart always -v /var/docker/mounts/jenkins_home:/var/jenkins_home --name jenkins -p 8080:8080 jenkins fi # docker Command to run the Jenkins Updater $ docker run --rm -d -v /var/lib/docker:/var/lib/docker -v /var/run/docker.sock:/var/run/docker.sock -v/var/docker/mounts:/var/docker/mounts dockerinpractice/jenkins-updater # to automate the process add this command to crontab 0 * * * * dokcker_command . . 10.7 CD Operations with Docker . CD : Continious Delivery ( CI + Deployment ) . # Copy an Image Between Two Registries Process =&gt; Pulling the image from the registry -&gt; retag -&gt; pushing the new Image $ docker tag -f $OLDREG/$MYIMAGE $NEWREG/$MYIMAGE $ docker push $NEWREG/$MYIMAGE $ docker rmi $OLDREG/$MYIMAGE $ docker image prune -f # Copy an Image btw Two Machine With a very low-bandwidth Connection Process =&gt; Here we use backup tool called Bup ( creates a bup data tool ) # Example ( Not Exact data is used so please Don&#39;t judge me ) # pull two images like Ubuntu:18.04 &amp; 19.10 ( Both are example = 65 MB Each = 130 MB ) $ mkdir bup_pool $ alias dbup=&quot;docker run --rm -v $(pwd)/bup_pool:/pool -v /var/run/docker.sock:/var/run/docker.sock dockerinpractice/dbup&quot; $ dbup save ubuntu:18.04 $ du -sh bup_pool ( 74 MB ) $ dbup save ubuntu:19.10 $ du -sh bup_pool ( 96 MB ) ( Saves 35 MB ) # On other machine ( rsync from host1 to host2 ) $ dbup load ubuntu:18.04 # Also copies files between host with TAR Docker export : creates Container To TAR Docker Import : TAR to Image Docker save : Image To TAR Docker load : TAR to Docker Image Example : Transfer docker Image directory over ssh $ docker export $(docker run -d debian:7.3 true) | ssh user@host docker import . . 10.8 Cordination Between Containers . We need coordination between containers : Like if we take an example of one server and one python based echo client. P1: If we start the client container first : It will lead to failure P2 : forgetting to remove the containers will result in problems when you try to restart P3 : Naming containers incorrectly will result in failure. So how to get rid of this types of problem : we need a solution,where we can run the container without any problem. . # Solution : create a compose file version: &quot;3&quot; services: echo-server: image: server expose: - &quot;2000&quot; client: image: client links: - echo-server:talkto # with this we can start container in correct order &amp; also we call rebuild the container anywhere $ docker-compose up Attaching to dockercompose_server_1, dockercompose_client_1 client_1 | Received: Hello, world client_1 | client_1 | Received: Hello, world client_1 | . . . 11.0 Security With Docker . . This is where security tips about Docker go. The Docker security page goes into more detail. . First things first: Docker runs as root. If you are in the docker group, you effectively have root access. If you expose the docker unix socket to a container, you are giving the container root access to the host. . Docker should not be your only defense. You should secure and harden it. . For an understanding of what containers leave exposed, you should read Understanding and Hardening Linux Containers by Aaron Grattafiori. This is a complete and comprehensive guide to the issues involved with containers, with a plethora of links and footnotes leading on to yet more useful content. The security tips following are useful if you’ve already hardened containers in the past, but are not a substitute for understanding. . 11.1 Security Tips . For greatest security, you want to run Docker inside a virtual machine. This is straight from the Docker Security Team Lead – slides / notes. Then, run with AppArmor / seccomp / SELinux / grsec etc to limit the container permissions. See the Docker 1.10 security features for more details. . Docker image ids are sensitive information and should not be exposed to the outside world. Treat them like passwords. . See the Docker Security Cheat Sheet by Thomas Sjögren: some good stuff about container hardening in there. . Check out the docker bench security script, download the white papers. . Snyk’s 10 Docker Image Security Best Practices cheat sheet . You should start off by using a kernel with unstable patches for grsecurity / pax compiled in, such as Alpine Linux. If you are using grsecurity in production, you should spring for commercial support for the stable patches, same as you would do for RedHat. It’s $200 a month, which is nothing to your devops budget. . Since docker 1.11 you can easily limit the number of active processes running inside a container to prevent fork bombs. This requires a linux kernel &gt;= 4.3 with CGROUP_PIDS=y to be in the kernel configuration. . docker run --pids-limit=64 . Also available since docker 1.11 is the ability to prevent processes from gaining new privileges. This feature have been in the linux kernel since version 3.5. You can read more about it in this blog post. . docker run --security-opt=no-new-privileges . From the Docker Security Cheat Sheet (it’s in PDF which makes it hard to use, so copying below) by Container Solutions: . Turn off interprocess communication with: . docker -d --icc=false --iptables . Set the container to be read-only: . docker run --read-only . Verify images with a hashsum: . docker pull debian@sha256:a25306f3850e1bd44541976aa7b5fd0a29be . Set volumes to be read only: . docker run -v $(pwd)/secrets:/secrets:ro debian . Define and run a user in your Dockerfile so you don’t run as root inside the container: . RUN groupadd -r user &amp;&amp; useradd -r -g user user USER user . 11.2 Security Videos . Using Docker Safely | Securing your applications using Docker | Container security: Do containers actually contain? | Linux Containers: Future or Fantasy? | . 11.3 Security Roadmap . The Docker roadmap talks about seccomp support. There is an AppArmor policy generator called bane, and they’re working on security profiles. . . Till 21 Aprill . Path to Complete . Docker access | Security Measures In Docker | Securing Access to Docker | Security from Outside docker | . . 12.0 Monitoring Docker . 12.1 Monitoring . . 12.2 Resource Control . . 12.3 Some Advance Approches .",
            "url": "https://hacstac.github.io/Notes/markdown/2020/09/01/Docker-Hard-Parts.html",
            "relUrl": "/markdown/2020/09/01/Docker-Hard-Parts.html",
            "date": " • Sep 1, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Docker Easy Parts",
            "content": "1.0 What is a Docker . . 1.1 Introduction . Defination : Docker is a tool designed to make it easier to create, deploy, and run applications by using containers. Containers allow a developer to package up an application with all of the parts it needs, such as libraries and other dependencies, and ship it all out as one package. . Docker container technology was launched in 2013 as an open source Docker Engine. Containers encapsulate an application as a single executable package of software that bundles application code together with all of the related configuration files, libraries, and dependencies required for it to run. . Containerized applications are “isolated” in that they do not bundle in a copy of the operating system. Instead, an open source Docker engine is installed on the host’s operating system and becomes the conduit for containers to share an operating system with other containers on the same computing system. . . . 1.2 Below is a list of common Docker terms . Docker Engine is a client-server application with 3 major components - a server which is a type of long-running program called a daemon process; a REST API which specifies interfaces that programs can use to talk to the daemon and instruct it what to do; a command line interface (CLI) client. . | Docker daemon (dockerd) listens for Docker API requests and manages Docker objects such as images, containers, networks, and volumes. . | Docker client (docker) is the primary way that many Docker users interact with Docker. When you use commands such as docker run, the client sends these commands to dockerd, which carries them out. The docker command uses the Docker API. The Docker client can communicate with more than one daemon. . | Image is a read-only template with instructions for creating a Docker container. You might create your own images or you might only use those created by others and published in a registry. To build your own image, you create a Dockerfile with a simple syntax for defining the steps needed to create the image and run it. . | Docker registry stores Docker images. Docker Hub is a public registry that anyone can use, and Docker is configured to look for images on Docker Hub by default. . | Container is a runnable instance of an image. Containers are made possible by operating system (OS) process isolation and virtualization, which enable multiple application components to share the resources of a single instance of an OS kernel. . | . 1.3 Architecture of docker . Docker on your host machine is (at the time of writing) split into two parts—a daemon with a RESTful API and a client that talks to the daemon. You invoke the Docker client to get information from or give instructions to the daemon; the daemon is a server that receives requests and returns responses from the client using the HTTP protocol. In turn, it will make requests to other services to send and receive images, also using the HTTP protocol. The server will accept requests from the command-line client or anyone else authorized to connect. The daemon is also responsible for taking care of your images and containers behind the scenes, whereasthe client acts as the intermediary between you and the RESTful API. . . . . . 2.0 Installation . . Docker can operate on most of the Operating Systems In Industries : Windows, MacOS, Most Of flavours of Linux ( Ubuntu, RHEL, Arch) | Docker Operates on both AMD64 and ARM Based Systems | . # Simple script to install docker on Linux $ curl -sSL https://get.docker.com/ | sh # Check Docker Verison $ docker version --format &#39;&#39; 19.03.8 # Dump Raw JSON DATA : Like Kernel, Architecture , details , build time etc $ docker version --format &#39;&#39; # Running Docker without sudo $ sudo usermod -aG docker username or $ sudo addgroup -a username docker # restart docker . . . 3.0 Docker Basics . . 3.1 Day To Day Docker Commands . . docker create creates a container but does not start it. | docker rename allows the container to be renamed. | docker run creates and starts a container in one operation. | docker rm deletes a container. | docker update updates a container’s resource limits. | docker images shows all images. | docker cp copies files or folders between a container and the local filesystem. | docker build creates image from Dockerfile. | docker commit creates image from a container, pausing it temporarily if it is running. | docker rmi removes an image. . | docker start starts a container so it is running. | docker stop stops a running container. | docker restart stops and starts a container. | docker pause pauses a running container, “freezing” it in place. | docker unpause will unpause a running container. | docker wait blocks until running container stops. | docker kill sends a SIGKILL to a running container. | docker attach will connect to a running container. . | docker ps shows running containers. | docker logs gets logs from container. (You can use a custom log driver, but logs is only available for json-file and journald in 1.10). | docker inspect looks at all the info on a container (including IP address). | docker events gets events from container. | docker port shows public facing port of container. | docker top shows running processes in container. | docker stats shows containers’ resource usage statistics. | docker diff shows changed files in the container’s FS. | docker history shows history of image. | docker tag tags an image to a name (local or registry). | . . 3.2 Getting Practical . . 3.2.1 List Images . docker images // show images docker ps -a docker ps // shows started containers -a = all containers . 3.2.2 Start/Stop/Restart . docker stop/start/restart . Note : If you want to detach from a running container, use Ctrl + P, Ctrl + Q. If you want to integrate a container with a host process manager, start the daemon with -r=false then use docker start -a. . 3.2.3 Logs . docker logs {Name_of_container} . 3.2.4 Rename . docker rename new_name current_name // rename container . 3.2.5 Create container . docker create nginx // will only create a container . 3.2.6 Example Run . $ docker run --interactive --tty --link web:web --name web_test busybox:1.29 /bin/sh -d = detach automatically the container (run container in background and print container ID) --interactive --tty or -t that will allocate a pseudo-TTY session --link = link to other container --name = name of docker container $ docker exec web_test ps // show extra process run with this containers . 3.2.7 Docker Run with SHELL Variables . CID=$(docker create nginx:latest) echo $CID // assigns to a Shell variable MAILER_CID=$(docker run -d dockerinaction/ch2_mailer) WEB_CID=$(docker create nginx) $ docker start $AGENT_CID $ docker start $WEB_CID . 3.2.8 Env Variables . $ docker run -d --name wpdb -e MYSQL_ROOT_PASSWORD=ch2demo mysql:5.7 $ docker run --env MY_ENVIRONMENT_VAR=&quot;this is a test&quot; busybox:1.29 env # --env flag, or -e for short, can be used to inject any environment variable. . 3.2.9 With Read Only Option . docker run -d --name wp --read-only wordpress:5.0.0-php7.2-apache // create a container with only readonly options . 3.2.10 Inspect . # The docker inspect command will display all the metadata(JSON) $ docker inspect --format &quot;&quot; wp // Prints true if container is running $ docker inspect --format &quot;&quot; Id/name // Show ip of container . 3.2.11 Diff ( Filesystem check ) . $ docker run -d --name wp_writable wordpress:5.0.0-php7.2-apache # let’s check where Apache changed the container’s filesystem with the docker $ docker container diff wp_writable A - A file or directory was added D - A file or directory was deleted C - A file or directory was changed C /run C /run/apache2 A /run/apache2/apache2.pid . 3.2.12 Clean Up . docker rm -f {container_ID) docker rm -vf $(docker ps -a -q) docker rmi [name] // Remove an image . 3.2.13 Executing Commands . # docker exec to execute a command in container. # To enter a running container, attach a new shell process to a running container called foo, use: $ docker exec -it foo /bin/bash. # exec Modes : # 1 Basic : Runs the command in the container synchronously on the command line $ docker exec name_of_container echo &quot;Hello User&quot; Hello User # 2 Daemon : Runs the command in the background on the container $ docker exec -d name_C find / -ctime 7 -name &#39;*log&#39; -exec rm {} ; # 3 Interactive : Runs the command and allows the user to interact with it $ docker exec -it ubuntu /bin/bash . 3.2.15 Linking containers for port isolation . Note : This is an older method of declaring container communication—Docker’s link flag. This isn’t the recommended way of working anymore. . # Example # This will allow us communication between containers without using user-defined networks. $ docker run --name wp-mysql -e MYSQL_ROOT_PASSWORD=yoursecretpassword -d mysql $ docker run --name wordpress --link wp-mysql:mysql -p 10003:80 -d wordpress . 3.2.16 Search a Docker Image . docker search node docker pull node // Pull the Image by Name ( on Hub ) docker run -it node /bin/bash ( Start Node Container ) . 3.2.17 Cleanly Kill Containers . # Always use docker stop ( it actually stops the containers ). # Docker kill will send immediate signal which will kill process while running ( so they can create temp files ) kill Term 15 docker kill Kill 9 docker stop Term 15 . 3.2.18 Docker Prune . # Prune commands docker system prune docker volume prune docker network prune docker container prune docker image prune # Example # Nuclear Option ( if you want to remove all containers of your host machine ) [Removes all : Runnig &amp; exited] $ docker ps -a -q | xargs --no-run-if-empty docker rm -f # To keep running containers $ docker ps -a -q --filter status=exited | xargs --no-run-if-empty docker rm # To list out all exited &amp; failed Containers $ comm -3 &lt;(docker ps -a -q --filter=status=exited | sort) &lt;(docker ps -a -q --filter=exited=0 | sort) | xargs --no-run-if-empty docker inspect &gt; error_containers # Prune Volumes # List out all docker voluems $ docker volume ls # Delete Unused Volumes $ docker volume prune . 3.2.19 Space Occupied By docker System . $ docker system df TYPE TOTAL ACTIVE SIZE RECLAIMABLE Images 7 1 1.963GB 1.885GB (95%) Containers 1 1 0B 0B Local Volumes 2 1 242.4MB 242.3MB (99%) Build Cache 0 0 0B 0B . 3.2.20 Container Stats . $ docker stats ID CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS . 3.2.21 Tag . docker image tag ubuntu-git:latest ubuntu-git:2.7 . 3.2.22 Commit . $ docker container commit -a &quot;@dockerinaction&quot; -m &quot;Added git&quot; image-dev ubuntu-git # Outputs a new unique image identifier like: # bbf1d5d430cdf541a72ad74dfa54f6faec41d2c1e4200778e9d4302035e5d143 # Build a New Image For Commited Image $ docker container run -d ubuntu-git . 3.2.23 Set an EntryPoint . docker container run --name cmd-git --entrypoint git ubuntu-git . . 3.2.24 Versioning Best Practice . # Docker official Repo&#39;s are the best example of tagging an image # Example for go lang 1.x 1.9 1.9.6 1.9-stretch 1.10-alpine latest # this is an example of tags to build that don&#39;t confuse the end user . . 3.3 States of Docker . Docker container can be in one of six states: . Created | Running | Restarting | Paused | Removing | Exited (also used if the container has never been started) | . . Created : A container that has been created (e.g. with docker create) but not started | Running : A currently running container | Paused : A container whose processes have been paused | Exited : A container that ran and completed (“stopped” in other contexts, although a created container is technically also “stopped”) | Dead : A container that the daemon tried and failed to stop (usually due to a busy device or resource used by the container) | Restarting : A container that is in the process of being restarted | . 3.3.1 Restart State . Using the --restart flag at container-creation time, you can tell Docker to do any of the following: . Never restart (default) | Attempt to restart when a failure is detected | Attempt for some predetermined time to restart when a failure is detected | Always restart the container regardless of the condition . | Methods no = = Don’t restart when the container exits | always == Always restart when the container exits | unless-stopped == Always restart, but remember explicitly stopping | on-failure[:max-retry] == Restart only on failure | . | . # Example Run $ docker run -d --name backoff-detector --restart always busybox:1.29 date $ docker logs -f backoff-detector . . 3.4 Init &amp; PID Systems for Docker . Several such init systems could be used inside a container. The most popular include runit, Yelp/dumb-init, tini, supervisord, and tianon/gosu . . $ docker run -d -p 80:80 --name lamp-test tutum/lamp $ docker top lamp-test $ docker exec lamp-test ps $ docker exec lamp-test kill &lt;PID&gt; // kill a process $ docker run --entrypoint=&quot;cat&quot; wordpress:5.0.0-php7.2-apache /usr/local/bin/docker-entrypoint.sh # If you run through the displayed script, you’ll see how it validates the environment variables against the dependencies of the software and sets default values. Once the script has validated that WordPress can execute . . 3.5 Software Installation Simplified . Three main ways to install Docker images: . Using Docker registries | Using image files with docker save and docker load | Building images with Dockerfiles | . we can install software in three other ways: . You can use alternative repository registries or run your own registry. | You can manually load images from a file. | You can download a project from some other source and build an image by using a provided Dockerfile. | . Note : - Keep in mind for Tags with images [latest, stable, alpha, Beta] . Download image from another regestry instead of docker hub : docker pull quay.io/dockerinaction/ch3_hello_registry:latest | [REGISTRYHOST:PORT/][USERNAME/]NAME[:TAG] | . 3.5.1 Installing Images using dockerfile . git clone https://github.com/dockerinaction/ch3_dockerfile.git docker build -t dia_ch3/dockerfile:latest ch3_dockerfile . . 3.6 Backup &amp; Restore Docker Images . docker export turns container filesystem into tarball archive stream to STDOUT. | docker import creates an image from a tarball. | docker load loads an image from a tar archive as STDIN, including images and tags (as of 0.7). | docker save saves an image to a tar archive stream to STDOUT with all parent layers, tags &amp; versions (as of 0.7). | . 3.6.1 Comparison . Docker export : Container To TAR Docker Import : TAR to Image Docker save : Image To TAR Docker load : TAR to Image . 3.6.2 Getting Practical . $ docker login/logout // get access to private repo on docker hub $ docker save [image_name] $ docker save -o myfile.tar image_name:latest // saves tar file in current directory $ docker load –i myfile.tar # Load/Save image - Load an image from file: $ docker load &lt; my_image.tar.gz # Save an existing image: $ docker save my_image:my_tag | gzip &gt; my_image.tar.gz # Import/Export container # Import a container as an image from file: $ cat my_container.tar.gz | docker import - my_image:my_tag # Export an existing container: $ docker export my_container | gzip &gt; my_container.tar.gz # Difference between loading a saved image and importing an exported container as an image Loading an image using the load command creates a new image including its history. Importing a container as an image using the import command creates a new image excluding the history which results in a smaller image size compared to loading an image. # Save the State of Docker Image: # we can save the state of image by commiting ( like we do in source control ) $ docker commit my_container # Creates a new Image ID # Restore State of Conatiner $ docker run [options] New_Image_ID # There is problem here. Docker Images ID&#39;s are 256Bit long, So there is no way to remember. what stuff we commit ( solution : is Tagging ) # Tag $ docker tag ID_OF_IMAGE imagename $ docker run imagename ( instead of 256Bit long ID ) # We can also Reffer to a specific image in builds # mention ID of Specific Build of Image ( like we did in previous steps ) and use it docker file. # Remember : This is image is locally available ( docker is not looking this on Docker HUB ) FROM 8eaa4ff06b53 ## Walkthrough of Saving States # Install 2048 Game ( for this we need VNC viewer ( TigerVNC ) $ docker run -d -p 5901:5901 -p 6080:6080 --name win2048 imiell/win2048 $ vncviewer localhost:1 (:1 If you have no X display on host ) # connect to port 5901 &amp; default password for vnc viewer is &#39;vncpass&#39; # Save a Game ( Commit Container ) $ docker commit win2048 1((co14-1)) $ docker tag ID 2048tag:$(date +%s) # Return To the Save Game $ docker run -d -p 5901:5901 -p 6080:6080 --name win2048 my2048tag:$mytag . . 3.7 Generating Dependency graph of Docker Image . # genrate a tree of dependecies of image $ git clone https://github.com/docker-in-practice/docker-image-graph $ cd docker-image-graph $ docker build -t dockerinpractice/docker-image-graph $ docker run --rm -v /var/run/docker.sock:/var/run/docker.sock dockerinpractice/docker-image-graph &gt; docker_images.png . . 3.8 Tricks for Making an Image Smaller . 3.8.1 Method 1 : Reduce the size of Third Party Image . # Step 1 : Remove Unnecessary file # Step 2 : Flatten the Image ( describe in this book ) # Step 3 : Check Which Packages we dont need ( $ dpkg -l | awk &#39;{print $2}&#39; # Step 4 : Remove Packages ( apt-get purge -y package name ) # Step 5 : Clean the cache ( apt-get autoremove, apt-get clean ) # Step 6 : Remove all the man pages and other doc files : $ rm -rf /usr/share/doc/* /usr/share/man/* /usr/share/info/* # Step 7 : Clean the Temp data &amp; logs in (/var) $ find /var | grep &#39; .log$&#39; | xargs rm -v # Step 8 : Commit The Image ( These Steps Creates a Much Smaller Image ) . 3.8.2 Method 2 : Tiny Docker Images with BusyBox and Alpine . Small, usable OSs that can be embedded onto a low-power or cheap computer have existed since Linux began. . # BusyBox ( Weight of BusyBox 2.5 MB ) # BusyBox is so small ( so it can&#39;t uses the bash. It uses ash ) $ docker run -it busybox /bin/ash # problem is that busybox don&#39;t uses any package manager : so for installing packages $ docker run -it progrium/busybox /bin/ash (Size: 5 MB ) # its uses opkg package manager $ opkg-install bash &gt; /dev/null $ bash ( Size of contianer is 6 MB with Bash Shell ) ( get ready to play with bash ) # Alpine ( 36 MB ) Package Manager : APK FROM gliderlabs/alpine:3.6 RUN apk-install mysql-client ENTRYPOINT [&quot;mysql&quot;] list of packages : https://pkgs.alpinelinux.org/packages . 3.8.3 Method 3 : The GO model of minimal containers . # we can minimal Web server with go [ 5 MB Web Server ] https://github.com/docker-in-practice/go-web-server Dockerfile FROM golang:1.4.2 RUN CGO_ENABLED=0 go get -a -ldflags &#39;-s&#39; -installsuffix cgo github.com/docker-in-practice/go-web-server CMD [&quot;cat&quot;,&quot;/go/bin/go-web-server&quot;] $ docker build -t go-webserver . $ mkdir -p go-web-server &amp;&amp; cd go-web-server $ docker run go-webserver &gt; go-web-server $ chmod +x go-web-server $ echo Hi &gt; page.html FROM scratch ADD go-web-server /go-web-server ADD page.html /page.html ENTRYPOINT [&quot;/go-web-server&quot;] $ docker build -t go-web-server . $ docker images | grep go-web-server $ docker run -p 8080:8080 go-web-server -port 8080 . Note : Remember One Large image is much efficient than some small images : Because it saves space on your HDD and save network bandwidth also &amp; Easy to maintainable. . Example : One Ubuntu Image with Node, Python, Nginx and other services ( around 1GB) (assigns only 1 IP) Many small container are request internet ( so they consume bandwidth more &amp; also they will consume more space than 1 GB ) . . . 4.0 Storage Volumes . . 4.1 Day To Day Volumes Command . docker volume create | docker volume rm | docker volume ls | docker volume inspect | . . 4.2 Types of Volumes . The three most common types of storage mounted into containers: . Bind mounts | In-memory storage | Docker volumes | . 4.2.1 Bind Mounts . Bind mounts are mount points used to remount parts of a filesystem tree onto other locations. When working with containers, bind mounts attach a user-specified location on the host filesystem to a specific point in a container file tree. . CONF_SRC=~/example.conf; CONF_DST=/etc/nginx/conf.d/default.conf; LOG_SRC=~/example.log; LOG_DST=/var/log/nginx/custom.host.access.log; docker run -d --name diaweb --mount type=bind,src=${CONF_SRC},dst=${CONF_DST} --mount type=bind,src=${LOG_SRC},dst=${LOG_DST} -p 80:80 nginx:latest . 4.2.2 In-Memory Storage . Most service software and web applications use private key files, database passwords, API key files, or other sensitive configuration files, and need upload buffering space. In these cases, it is important that you never include those types of files in an image or write them to disk. Instead, you should use in-memory storage. You can add in-memory storage to containers with a special type of mount. . # 1777 permissions in octal # tmpfs-size=16k memory-based filesystem into a containerdocker run --rm --mount type=tmpfs,dst=/tmp,tmpfs-size=16k,tmpfs-mode=1770 --entrypoint mount alpine:latest -v . 4.2.3 Docker Volumes . Docker volumes are named filesystem trees managed by Docker. They can be implemented with disk storage on the host filesystem, or another more exotic backend such as cloud storage. All operations on Docker volumes can be accomplished using the docker volume subcommand set. . . docker volume create --driver local --label example=location location-example docker volume inspect --format &quot;&quot; location-example . . 4.3 Moving Docker to a different Partition . # Stop Docker Daemon ( service docker stop ) $ $ dockerd -g /home/dockeruser/mydocker . Note : This will wipe all the containers and images from your previous Docker daemon. . . 4.4 Access Filesystem from Docker Container . # This will mount /dotfiles folder to container $ docker run -v /home/hacstac/dotfiles:~/dotfiles -t debian bash . . 4.5 Share Volumes Across the internet . # In this we use a technology called Resilio # Example ( 2 Machines ) : Setup Resilio on both Machine - That synchronized a volume ( Connected through a Secret Key ) # Machine 1 $ docker run -d -p 8888:8888 -p 55555:55555 --name resilio ctlc/btsync # docker logs resilio Or ( Lazy ) -&gt; Use Portainer ( Logs ) # copy secret key $ docker run -it --volumes-from resilio ubuntu /bin/bash # create Data in ubuntu : touch /data/shared_from_server # Machine 2 # setup resilio client $ docker run -d --name resilio-client -p 8888:8888 -p 55555:55555 ctlc/btsync key_of_server # Setup ubuntu $ docker run -it --volumes-from resilio-client ubuntu /bin/bash # our data folder is now available in this &amp; if you create a file in here then it will synchronized to Machine 1 also. . . 4.6 Using a Centralized Data Volumes For Containers . # Create a volume with docker which store a data which you need in other docker containers $ docker run -v /codebase --name codebase busybox # access the codebase $ docker run -it --volumes-from codebase ubuntu /bin/bash . . 4.7 Mounting the remote file systems . # This will need FUSE Kernel Module to be loaded on Host OS ( filesystem and userspace ) # Required Root Access ( Danger ) # 4.7.1. SSHFS # Local Host $ docker run -it --privileged debian /bin/bash # Inside a Container $ sudo apt-get update &amp;&amp; apt-get install sshfs $ LOCALPATH=/path/to/directory/ $ mkdir $LOCALPATH $ sshfs -o nonempty user@host:/path/to/directory $LOCALPATH # to unmount fusermount -u /path/to/local/directory # Now the remote folder is mount on LOCALPATH # 4.7.2 NFS # Install a NFS on host ( because docker doesn&#39;t support NFS ) $ apt-get install nfs-kernel-server $ mkdir /export $ chmod 777 /export $ mount --bind /opt/test/db /export # add this to fstab ( if you want to persist over reboot ) /etc/fstab file: /opt/test/db /export none bind 0 0 # add this to /etc/exports /export 127.0.0.1(ro,fsid=0,insecure,no_subtree_check,async) # to Read/Write : change ro to rw &amp; add no_root_squash (After async) # To open to the internet replace localhost to * ( Danger : Think about it ) $ mount -t nfs 127.0.0.1:/export /mnt $ exportfs -a $ service nfs-kernel-server restart # Run a container $ docker run -it --name nfs-client --privileged -v /mnt:/mnt busybox /bin/true # Mount on other container $ docker run -it --volumes-from nfs-client debian /bin/bash . . . 5.0 Networks in Docker . . 5.1 Day To Day Network Commands . docker network create | docker network rm | docker network ls | docker network inspect | docker network connect | docker network disconnect | . . 5.2 Examples . 5.2.1 To list all networks . $ docker network ls NETWORK ID NAME DRIVER SCOPE f32f6d51e8c8 bridge bridge local 366d3d1f4719 hacstac_default bridge local 6c08bddba2c4 host host local b726554d155b none null local . 5.2.2 To Create a New Network . $ docker network create --driver bridge --label project=dockerinaction --label chapter=5 --attachable --scope local --subnet 10.0.42.0/24 --ip-range 10.0.42.128/25 user-network $ docker run -it --network user-network --name network-explorer alpine:3.8 sh # CTRL-P + CTRL-Q Detech # docker attach network-explorer # walkthrough $ docker network create my_network [ Create a Network ] $ docker network connect my_network blog1 [ blog1 container connect to a network my_network ] $ docker run -it --network my_network ubuntu:16.04 bash [ Now this ubuntu container have access to blog1 Container ] $ ip -f inet -4 -o addr // this will list loopback and assign ip subnet address . 5.2.3 Create a another bridge network . $ docker network create --driver bridge --attachable --scope local --subnet 10.0.43.0/24 --ip-range 10.0.43.128/25 user-network2 # Attach priviously created container attach to this network $ docker network connect user-network2 network-explorer # then this container lists two ethernet addresses # scan with nmap $ nmap -sn 10.0.42.* -sn 10.0.43.* -oG /dev/stdout | grep Status . 5.2.4 With Network - none : Means container with no external excess . $ docker run --rm --network none alpine:3.8 ping -w 2 1.1.1.1 # it will try to ping 1.1.1.1 but it failed because this container hace no external network access # NodePort Publishing # 8080:8000 will denote 8080 port of host machine and 8000 port of container $ docker run -d -p 8080 --name listener alpine:3.8 $ docker port listener // To view port of running container . 5.2.5 DNS with docker . # Feature 1 : --hostname will add hostname : so we open with DN $ docker run --rm --hostname barker alpine:3.8 nslookup barker Server: 10.0.2.3 Address 1: 10.0.2.3 Name: barker Address 1: 172.17.0.22 barker - # Feature 2 : --dns : set dns server on container $ docker run --rm --dns 8.8.8.8 alpine:3.8 nslookup docker.com # Feature 3 : --dns-search : allows us to specify a DNS searchdomain, which is like a default hostname suffix $ docker run --rm --dns-search docker.com --dns 1.1.1.1 alpine:3.8 cat /etc/resolv.conf # Will display contents that look like: # search docker.com # nameserver 1.1.1.1 # Feature 4 : --add-host $ docker run --rm --hostname mycontainer --add-host docker.com:127.0.0.1 --add-host test:10.10.10.2 alpine:3.8 cat /etc/hosts 172.17.0.45 mycontainer 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopbackfe00 ::0 ip6-localnetff00::0 ip6-mcastprefixff02 ::1 ip6-allnodesff02::2 ip6-allrouters 10.10.10.2 test 127.0.0.1 docker.com . 5.2.6 You can specify a specific IP address for a container . # create a new bridge network with your subnet and gateway for your ip block $ docker network create --subnet 203.0.113.0/24 --gateway 203.0.113.254 iptastic # run a nginx container with a specific ip in that block $ docker run --rm -it --net iptastic --ip 203.0.113.2 nginx # curl the ip from any other place (assuming this is a public ip block duh) $ curl 203.0.113.2 . 5.2.7 Open a Docker Daemon to the World . # first of stop the docker service $ sudo service docker stop / or $ sudo systemctl stop docker # Checks for docker daemon ?? $ ps -ef | grep -E &#39;docker(d| -d| daemon) b&#39; | grep -v grep # Expose to local host : 2375 $ sudo docker daemon -H tcp://0.0.0.0:2375 # To connect $ docker -H tcp://&lt;your host&#39;s ip&gt;:2375 &lt;subcommand&gt; . 5.2.8 Get an IP &amp; Ports of a Docker Container . $ alias dl=&#39;docker ps -l -q&#39; ( latest container ID ) $ docker inspect $(dl) | grep -wm1 IPAddress | cut -d &#39;&quot;&#39; -f 4 Pass ( ID of container Instead of dl ) : this above command gives ip of latest container # get ports $ docker inspect -f &#39; -&gt; &#39; 274d2292a137 | name_of_container . . . 6.0 Limiting Risk with Resource Controls . . 6.1 Memory Limits . $ docker container run -d --name ch6_mariadb --memory 256m --cpu-shares 1024 --cap-drop net_raw -e MYSQL_ROOT_PASSWORD=test mariadb:5.5 # This container only uses the 256M memory . . 6.2 CPU Limits . $ docker container run -d -P --name ch6_wordpress --memory 512m --cpu-shares 512 --cap-drop net_raw --link ch6_mariadb:mysql -e WORDPRESS_DB_PASSWORD=test wordpress:5.0.0-php7.2-apache # if total cpu share is 1536 - 512 ( 33% ) : this container consume 33% of cpu shares $ docker container run -d -P --name ch6_wordpress --memory 512m --cpus 0.75 --cap-drop net_raw --link ch6_mariadb:mysql -e WORDPRESS_DB_PASSWORD=test wordpress:5.0.0-php7.2-apache # This Container : consumed max 75% of cpu cores # also we can use {--cpuset-cpus 0-4} (cores) . . 6.3 Access to devices . $ docker container run -it --rm --device /dev/video0:/dev/video0 ubuntu:16.04 ls -al /dev # --device flag will mount external device to container . . 6.4 Sharing Memory ( IPC : Interprocess Communication ) . # Producer $ docker container run -d -u nobody --name ch6_ipc_producer --ipc shareable dockerinaction/ch6_ipc -producer # Consumer $ docker container run -d --name ch6_ipc_consumer --ipc container:ch6_ipc_producer dockerinaction/ch6_ipc -consumer # we can see the process of one container in another : by using docker logs { they share the memory space } # IMP NOTE : In docker to clean Volumes $ docker rm -vf name_of_container . . 6.5 Understanding Users . # if we want to setup a container with diff user then $ docker container run --rm --user nobody busybox:1.29 id $ docker container run --rm -u 1000:1000 busybox:1.29 /bin/bash -c &quot;echo This is important info &gt; /logFiles/important.log&quot; # with this userID:GroupID we can access the file system of this users . . 6.6 OS features Access with Capabilities . Linux capabilities can be set by using cap-add and cap-drop. See https://docs.docker.com/engine/reference/run/#/runtime-privilege-and-linux-capabilities for details. This should be used for greater security. . SYS_MODULE —Insert/remove kernel modules SYS_RAWIO — Modify kernel memory SYS_NICE — Modify priority of processes SYS_RESOURCE — Override resource limits SYS_TIME — Modify the system clock AUDIT_CONTROL — Configure audit subsystem MAC_ADMIN — Configure MAC configuration SYSLOG — Modify kernel print behavior NET_ADMIN — Configure the network SYS_ADMIN — Catchall for administrative functions $ docker container run --rm -u nobody --cap-add sys_admin ubuntu:16.04 /bin/bash -c &quot;capsh --print | grep sys_admin&quot; # this --cap-add sys_admin will add admin facilities to container # we can inspect docker with .HostConfig.CapAdd &amp;&amp; .HostConfig.CapDrop show capabilities # Give access to a single device: $ docker run -it --device=/dev/ttyUSB0 debian bash # Give access to all devices: $ docker run -it --privileged -v /dev/bus/usb:/dev/bus/usb debian bash # Docker Container with full privileges $ docker container run --rm --privileged ubuntu:16.04 capsh ls /dev # check out list of mounted devices . . 6.7 Additional Security with Docker . $ docker container run --rm -it --security-opt seccomp=path_to_the_secomp conf file ubuntu:16.04 sh # For Linux Security Modules ( LSM ) The LSM security option values are specified in one of seven formats: - To prevent a container from gaining new privileges after it starts, use &#39;no-new-privileges&#39; - To set a SELinux user label, use the form label=user:username, where is the name of the user you want to use for the label. - To set a SELinux role label, use the form label=role:role where is the name of the role you want to apply to processes in the container. - To set a SELinux type label, use the form label=type:type , where is the type name of the processes in the container. - To set a SELinux-level label, use the form &#39;label:level:label&#39; , where is the level at which processes in the container should run. Levels are specified as low-high pairs. Where abbreviated to the low level only, SELinux will inter-pret the range as single level. - To disable SELinux label confinement for a container, use the form label=disable # NOTE : Avoid Running Containers in privileged mode whenever possible . . 6.8 Using Socat to monitor docker api traffic . In this technique you’ll insert a proxy Unix domain socket between your request and the server’s socket to see what passes through it. Note that you’ll need root or sudo privileges to make this work. . # We need a socat ( Install socat as per the OS package Maneger ) $ socat -v UNIX-LISTEN:/tmp/dockerapi.sock,fork UNIX-CONNECT:/var/run/docker.sock &amp; In this command, -v makes the output readable, with indications of the flow of data.The UNIX-LISTEN part tells socat to listen on a Unix socket, fork ensures that socatdoesn’t exit after the first request, and UNIX-CONNECT tells socat to connect toDocker’s Unix socket. The &amp; specifies that the command runs in the background.If you usually run the Docker client with sudo, you’ll need to do the same thing here as well. # List all containers $ docker -H unix:///tmp/dockerapi.sock ps -a # This will show how client request to daemon . . 6.9 Setting TimeZone in Containers . # Runs a command to display the time zone on the host $ date +%Z // UTC # change TimeZone FROM centos:7 RUN rm -rf /etc/localtime RUN ln -s /usr/share/zoneinfo/Asia/Kolkata /etc/localtime CMD date +%Z # Build Image $ docker build -t timezone_change . $ docker run timezone_change Asia/Kolkata . . 6.10 Locale Management . locale will be set in the environment through the LANG,LANGUAGE, and locale-gen variables . # you are getting encoding error if correct locale is not set. # Check for locale $ env | grep LANG LANG=en_GB.UTF-8 This is British English, with text encoded in UTF-8. # Set Locale FROM ubuntu:16.04 RUN apt-get update &amp;&amp; apt-get install -y locales RUN locale-gen en_US.UTF-8 ENV LANG en_US.UTF-8 ENV LANGUAGE en_US:en CMD env $ $ docker build -t encoding . . . .",
            "url": "https://hacstac.github.io/Notes/markdown/2020/08/29/Docker-Easy-Parts.html",
            "relUrl": "/markdown/2020/08/29/Docker-Easy-Parts.html",
            "date": " • Aug 29, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://hacstac.github.io/Notes/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://hacstac.github.io/Notes/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}